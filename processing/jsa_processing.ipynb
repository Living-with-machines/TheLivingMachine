{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sentence_splitter import split_text_into_sentences\n",
    "from tqdm import tqdm, notebook\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../workspace/data/JSA_1854-1876/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "re_jsa_id = \"j[0-9]+\"\n",
    "for i in glob.glob(data_folder + \"metadata/*\"):\n",
    "    \n",
    "    filename = i.split(\"/\")[7].split(\".xml\")[0] # Adapt according to at\n",
    "    \n",
    "    # journal metadata\n",
    "    journal_id = \"\"\n",
    "    journal_id_text = \"\"\n",
    "    journal_title = \"\"\n",
    "    publisher_name = \"\"\n",
    "    \n",
    "    # article metadata\n",
    "    volume = \"\"\n",
    "    issue = \"\"\n",
    "    issue_id = \"\"\n",
    "    article_id = \"\"\n",
    "    first_page = \"\"\n",
    "    last_page = \"\"\n",
    "    uri = \"\"\n",
    "    title_group = \"\"\n",
    "    date = \"\"\n",
    "    contributors = []\n",
    "    \n",
    "    root = ET.parse(i).getroot()\n",
    "    for child in root.findall('front/journal-meta/'):\n",
    "        if child.tag == \"journal-id\":\n",
    "            if re.match(re_jsa_id, child.text):\n",
    "                journal_id = child.text\n",
    "            else:\n",
    "                journal_id_text = child.text\n",
    "        elif child.tag == \"journal-title-group\":\n",
    "            journal_title = child.find(\"journal-title\").text\n",
    "        elif child.tag == \"publisher\":\n",
    "            publisher_name = child.find(\"publisher-name\").text\n",
    "    \n",
    "    for child in root.findall('front/article-meta/'):\n",
    "        if child.tag == \"volume\":\n",
    "            volume = child.text\n",
    "        elif child.tag == \"issue\":\n",
    "            issue = child.text\n",
    "        elif child.tag == \"issue-id\":\n",
    "            issue_id = child.text\n",
    "        elif child.tag == \"article-id\":\n",
    "            article_id = child.text\n",
    "        elif child.tag == \"fpage\":\n",
    "            first_page = child.text\n",
    "        elif child.tag == \"lpage\":\n",
    "            last_page = child.text\n",
    "        elif child.tag == \"self-uri\":\n",
    "            uri = child.attrib[\"{http://www.w3.org/1999/xlink}href\"]\n",
    "        elif child.tag == \"title-group\":\n",
    "            title_group = child.find(\"article-title\").text\n",
    "        elif child.tag == \"contrib-group\":\n",
    "            for subchild in child.findall(\"contrib/\"):\n",
    "                contrib = dict()\n",
    "                if subchild.tag == \"string-name\":\n",
    "                    for subsubchild in subchild:\n",
    "                        contrib[subsubchild.tag] = subsubchild.text\n",
    "                else:\n",
    "                    contrib[subchild.tag] = subchild.text\n",
    "                contributors.append(contrib)\n",
    "        elif child.tag == \"pub-date\":\n",
    "            day = int(child.find(\"day\").text)\n",
    "            month = int(child.find(\"month\").text)\n",
    "            year = int(child.find(\"year\").text)\n",
    "            date = datetime.date(year, month, day)\n",
    "    rows.append([filename, journal_id, journal_id_text, journal_title, publisher_name,\n",
    "                 volume, issue, issue_id, article_id, first_page, last_page, uri,\n",
    "                 title_group, date, contributors])\n",
    "    \n",
    "df = pd.DataFrame(rows, columns=[\"filename\", \"journal_id\", \"journal_id_text\", \"journal_title\", \"publisher_name\", \"volume\",\n",
    "             \"issue\", \"issue_id\", \"article_id\", \"first_page\", \"last_page\", \"uri\", \"title_group\",\n",
    "             \"date\", \"contributors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"jsa_metadata.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fulltext(fulltext_path):\n",
    "    fulltext_path = data_folder + \"ocr/\" + fulltext_path + \".txt\"\n",
    "    sentences = []\n",
    "    if Path(fulltext_path).exists():\n",
    "        with open(fulltext_path) as fr:\n",
    "            re_pageheader = r\".*\\, [A-Z][A-Za-z]+ [0-9]{1,2}\\, [0-9]{4}\\.? ?[0-9]*\"\n",
    "            fulltext = fr.read()\n",
    "            fulltext = fulltext.split(\"<plain_text>\")[1]\n",
    "            fulltext = fulltext.split(\"</plain_text>\")[0]\n",
    "            fulltext = fulltext.split(\"</page>\")\n",
    "            fulltext = [x for x in fulltext if x]\n",
    "            text = \"\"\n",
    "            for pageseq in fulltext:\n",
    "                pageseq_num = re.match(\"\\<page sequence\\=\\\"([0-9]+)\\\"\\>\", pageseq).group(1)\n",
    "                pageseq = re.sub(\"\\<page sequence\\=\\\"([0-9]+)\\\"\\>\", \"\", pageseq).strip()\n",
    "                pageseq = re.sub(re_pageheader, \"\", pageseq).strip()\n",
    "                text += \" \" + pageseq\n",
    "            sentences = split_text_into_sentences(text=text, language='en')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentences'] = df.progress_apply(lambda x: parse_fulltext(x[\"filename\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"jsa_parsed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-phase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37animacy)",
   "language": "python",
   "name": "py37animacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
