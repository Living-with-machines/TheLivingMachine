{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca58224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cosine\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import explore_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTIONS!\n",
    "# Change the values in the `datasets` list to include the list of all datasets to\n",
    "# which you would like to apply this method.\n",
    "datasets = [\"example\"] # in our experiments, this was [\"JSA\", \"HMD\", \"BLB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f86f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTIONS!\n",
    "# You will need to download our Word2Vec model, pre-trained on the BL Books corpus (1760-1850) from Zenodo.\n",
    "# 1. Go to https://zenodo.org/record/4782245 and download the word2vec.zip file\n",
    "# 2. Unzip this file and place it a new folder called 'models' in the parent folder of your local 'TheLivingMachine' repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b892e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda x, target : 1 - cosine(x,target)\n",
    "\n",
    "# Read a word2vec model\n",
    "w2v_model = Word2Vec.load(\"./models/word2vec/w2v_1760_1850/w2v_words.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dWordClusters = dict()\n",
    "\n",
    "dWordClusters[\"stopwords\"] = stopwords.words('english')\n",
    "dWordClusters[\"punctuation\"] = [x for x in string.punctuation]\n",
    "dWordClusters[\"machines\"] = [\"instrument\", \"apparatus\", \"machine\", \"engine\",\n",
    "                             \"engines\", \"instruments\", \"tube\", \"cylinder\",\n",
    "                             \"machinery\", \"machines\", \"turbine\", \"turbines\",\n",
    "                             \"boiler\", \"boilers\", \"dynamo\", \"dynamos\", \"motor\",\n",
    "                             \"motors\", \"apparatuses\", \"accumulator\", \"accumulators\",\n",
    "                             \"compressor\", \"compressors\", \"piston\", \"valve\", \"pump\",\n",
    "                             \"pistons\", \"valves\", \"pumps\"]\n",
    "dWordClusters[\"transport\"] = [\"car\", \"cars\", \"cart\", \"carts\", \"boat\",\n",
    "                              \"boats\", \"ship\", \"ships\", \"carriage\", \"carriages\", \"train\", \n",
    "                              \"trains\", \"wagon\", \"wagons\", \"omnibus\", \"omnibuses\", \"ambulance\",\n",
    "                              \"ambulances\", \"steamer\", \"steamers\", \"locomotive\", \"locomotives\",\n",
    "                              \"vehicle\", \"vehicles\"]\n",
    "dWordClusters[\"workforce\"] = [\"worker\", \"workers\", \"manufacturer\", \"manufacturers\",\n",
    "                              \"slave\", \"slaves\", \"servant\", \"servants\", \"labourer\", \n",
    "                              \"labourers\", \"workman\", \"workmen\", \"workwoman\", \"workwomen\",\n",
    "                              \"employee\", \"employees\", \"craftsman\", \"craftsmen\", \"craftswoman\",\n",
    "                              \"craftswomen\", \"tradesman\", \"tradesmen\", \"tradeswoman\",\n",
    "                              \"tradeswomen\", \"shopkeeker\", \"shopkeekers\", \"merchant\", \n",
    "                              \"merchants\", \"dealer\", \"dealers\", \"trader\", \"traders\",\n",
    "                              \"tradesperson\", \"tradespersons\", \"artisan\", \"technician\",\n",
    "                              \"artisans\", \"technicians\", \"maker\", \"makers\", \"driver\",\n",
    "                              \"drivers\", \"child\", \"boy\", \"girl\", \"children\", \"boys\",\n",
    "                              \"girls\", \"lad\", \"man\", \"men\", \"woman\", \"women\",\n",
    "                              \"experts\", \"person\", \"persons\", \"people\"]\n",
    "dWordClusters[\"energy\"] = [\"energy\", \"power\", \"force\", \"motion\", \"electricity\", \"spark\",\n",
    "                           \"light\", \"flame\", \"powers\", \"heat\", \"gas\"]\n",
    "dWordClusters[\"upperclass\"] = [\"gentleman\", \"gentlemen\", \"king\", \"kings\",\n",
    "                               \"prince\", \"princes\", \"lady\", \"ladies\",\n",
    "                               \"princess\", \"princesses\", \"queen\", \"queens\"]\n",
    "dWordClusters[\"child\"] = [\"child\", \"boy\", \"girl\", \"children\", \"youth\", \"boys\",\n",
    "                          \"girls\", \"lad\", \"infant\", \"baby\"]\n",
    "dWordClusters[\"workanimal\"] = [\"animal\", \"animals\", \"dog\", \"dogs\", \"ass\", \"asses\",\n",
    "                               \"mule\", \"mules\", \"donkey\", \"donkeys\", \"beast\", \"beasts\",\n",
    "                               \"cow\", \"cows\", \"ox\", \"oxen\", \"pony\", \"ponies\", \"creature\",\n",
    "                               \"creatures\", \"bird\", \"birds\", \"cat\", \"cats\", \"horse\",\n",
    "                               \"horses\"]\n",
    "dWordClusters[\"spiritual\"] = [\"soul\", \"souls\", \"spirit\", \"spirits\", \"life\", \"lives\",\n",
    "                              \"idea\", \"ideas\", \"art\", \"arts\", \"god\", \"gods\", \"thought\",\n",
    "                              \"thoughts\", \"mind\", \"minds\", \"heart\", \"hearts\", \"angel\",\n",
    "                              \"angels\", \"demon\", \"demons\", \"virtue\", \"virtues\",\n",
    "                              \"brain\", \"brains\", \"instinct\", \"instincts\"]\n",
    "dWordClusters[\"body\"] = [\"body\", \"bodies\", \"organism\", \"tissue\", \"skeleton\",\n",
    "                         \"frame\", \"skeletons\", \"organisms\", \"tissues\", \"frames\"]\n",
    "dWordClusters[\"system\"] = [\"system\", \"systems\", \"plan\", \"plans\", \"scheme\", \"schemes\"]\n",
    "dWordClusters[\"nature\"] = [\"air\", \"water\", \"flame\", \"earth\", \"sun\", \"planet\",\n",
    "                           \"planets\", \"world\", \"wind\", \"storm\", \"weather\"]\n",
    "dWordClusters[\"slave\"] = [\"slave\", \"slaves\"]\n",
    "dWordClusters[\"female\"] = [\"woman\", \"women\", \"girl\", \"girls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9278f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dAvgVectors = dict()\n",
    "for c in dWordClusters:\n",
    "    dAvgVectors[c] = explore_preds.w2v_avg_embedding(dWordClusters[c], w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9448e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"experiments/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119a70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for corpus in datasets:\n",
    "    epochs = [\"1760_1850\", \"1890_1900\"]\n",
    "\n",
    "    df = pd.read_pickle(\"data/\" + corpus.lower() + \"_processed/\" + corpus + \"_machine_synparsed_pred_bert.pkl\")\n",
    "    dWordEmb = dict() # Dictionary where we keep embedding-cluster similarities, so we don't need to not find it every time\n",
    "\n",
    "    for epoch in epochs:\n",
    "\n",
    "        print(epoch)\n",
    "\n",
    "        sim_df = pd.DataFrame(columns=[\"df_id\"] + [x + \"_\" + epoch for x in list(dAvgVectors.keys())])\n",
    "        rows_list = []\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            preds_test = row[\"pred_bert_\" + epoch]\n",
    "            dClScores = dict()\n",
    "            for cl in dAvgVectors:\n",
    "                aggr_values = []\n",
    "                for pred in preds_test:\n",
    "                    if \"#\" in pred[0] and cl == \"punctuation\": # If it is a BERT subword, consider it as punctuation:\n",
    "                        aggr_values.append(pred[1] + 0.0001)\n",
    "                    elif pred[0] in dWordClusters[cl]:\n",
    "                        aggr_values.append(pred[1] + 0.0001) # To smooth rounded zero values\n",
    "                    elif dWordEmb.get(pred[0], {}).get(cl):\n",
    "                        aggr_values.append(dWordEmb[pred[0]][cl] * (pred[1] + 0.0001))\n",
    "                    else:\n",
    "                        try:\n",
    "                            tmp_emb = w2v_model.wv.get_vector(pred[0])\n",
    "                            clusterSim = cosine_similarity(tmp_emb, dAvgVectors[cl])\n",
    "                            aggr_values.append(clusterSim * (pred[1] + 0.0001))\n",
    "                            if pred[0] in dWordEmb:\n",
    "                                dWordEmb[pred[0]][cl] = clusterSim\n",
    "                            else:\n",
    "                                dWordEmb[pred[0]] = {cl:clusterSim}\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "\n",
    "                dClScores[cl + \"_\" + epoch] = round(sum(aggr_values), 3)\n",
    "            dClScores[\"df_id\"] = i\n",
    "            rows_list.append(dClScores)\n",
    "\n",
    "        sim_df = pd.DataFrame(rows_list)\n",
    "\n",
    "        df = df.merge(sim_df, left_index=True, right_on=\"df_id\")\n",
    "\n",
    "        df = df.drop(columns=[\"df_id\"])\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    df.to_csv(\"experiments/\" + corpus.lower() + \"_clusters.tsv\", sep=\"\\t\", index=False)\n",
    "    df.to_json(\"experiments/\" + corpus.lower() + \"_clusters.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39tlm)",
   "language": "python",
   "name": "py39tlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
