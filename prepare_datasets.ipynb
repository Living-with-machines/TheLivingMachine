{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c22c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd92891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_jsa\n",
    "from utils import process_rsc\n",
    "from utils import prepare_sents\n",
    "from utils import explore_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163ca76",
   "metadata": {},
   "source": [
    "#### Process  the JSA corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../workspace/data/\" # Path where JSA data is located\n",
    "output_path = \"data/jsa_processed/\"\n",
    "overwrite = False # If False, run the code only if output has not been created.\n",
    "                  # If True, run the code regardless.\n",
    "\n",
    "process_jsa.parse_corpus(input_path, output_path, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2c3a9",
   "metadata": {},
   "source": [
    "#### Process the RSC corpus\n",
    "\n",
    "Data downloaded from https://fedora.clarin-d.uni-saarland.de/rsc_v6/access.html#download.\n",
    "\n",
    "We are using:\n",
    "* TEI-formatted corpus [v6.0.4](https://fedora.clarin-d.uni-saarland.de/rsc_v6/data/texts/Royal_Society_Corpus_open_v6.0.4_texts_tei.zip) (as separate files).\n",
    "* Corresponding metadata [v6.0.4](https://fedora.clarin-d.uni-saarland.de/rsc_v6/data/Royal_Society_Corpus_open_v6.0.4_meta.tsv.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../workspace/data/RSC/\" # Path where JSA data is located\n",
    "output_path = \"data/rsc_processed/\"\n",
    "overwrite = False # If False, run the code only if output has not been created.\n",
    "                  # If True, run the code regardless.\n",
    "\n",
    "process_rsc.parse_corpus(input_path, output_path, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b35e70",
   "metadata": {},
   "source": [
    "#### Get sentences with machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7902d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the query tokens here:\n",
    "query_tokens = [\"machine\", \"machines\", \"engine\", \"engines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"JSA\"\n",
    "jsa_sents_df = prepare_sents.filter_sents_query(corpus, query_tokens)\n",
    "jsa_sents_df.to_csv(\"data/jsa_processed/JSA_machines.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ffb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"RSC\"\n",
    "rsc_sents_df = prepare_sents.filter_sents_query(corpus, query_tokens)\n",
    "rsc_sents_df = rsc_sents_df[(rsc_sents_df[\"year\"] >= 1783) & (rsc_sents_df[\"year\"] <= 1908)]\n",
    "rsc_sents_df.to_csv(\"data/rsc_processed/RSC_machines.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe841b",
   "metadata": {},
   "source": [
    "#### Syntactic filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "syndf = jsa_sents_df.copy()\n",
    "syndf['synt'] = prepare_sents.preprocess_pipe(syndf['currentSentence'], nlp)\n",
    "syndf = syndf[syndf.apply(lambda x: prepare_sents.filter_sents_synt(x.synt, x.targetExpression), axis=1)]\n",
    "syndf[\"query_label\"] = syndf.apply(lambda x: prepare_sents.find_query_deplabel(x.synt, x.maskedSentence, x.targetExpression), axis=1)\n",
    "syndf.to_pickle(\"data/jsa_processed/JSA_synparsed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b740743",
   "metadata": {},
   "outputs": [],
   "source": [
    "syndf = rsc_sents_df.copy()\n",
    "syndf['synt'] = prepare_sents.preprocess_pipe(syndf['currentSentence'], nlp)\n",
    "syndf = syndf[syndf.apply(lambda x: prepare_sents.filter_sents_synt(x.synt, x.targetExpression), axis=1)]\n",
    "syndf[\"query_label\"] = syndf.apply(lambda x: prepare_sents.find_query_deplabel(x.synt, x.maskedSentence, x.targetExpression), axis=1)\n",
    "syndf.to_pickle(\"data/rsc_processed/RSC_synparsed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd674fad",
   "metadata": {},
   "source": [
    "#### BERT masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"data/rsc_processed/RSC_synparsed.pkl\",\n",
    "                \"data/jsa_processed/JSA_synparsed.pkl\"]:\n",
    "    \n",
    "    if not Path(dataset.split(\".pkl\")[0] + \"_pred_bert.pkl\").is_file():\n",
    "        \n",
    "        print(dataset)\n",
    "\n",
    "        # Load dataframe where to apply this:\n",
    "        pred_df = pd.read_pickle(dataset)\n",
    "        for epoch in [\"1760_1850\", \"1850_1875\", \"1875_1890\", \"1890_1900\"]:\n",
    "\n",
    "            print(epoch)\n",
    "\n",
    "            # Create pipeline depending on the BERT model of the specified period\n",
    "            # and the number of expected predictions:\n",
    "            pred_toks = 10\n",
    "            model_rd = explore_preds.create_mask_pipeline(epoch, pred_toks)\n",
    "\n",
    "            # Use BERT to find most likely predictions for a mask:\n",
    "            pred_df[\"pred_bert_\" + epoch] = pred_df.apply(lambda x: explore_preds.bert_masking(x, model_rd), axis=1)\n",
    "\n",
    "        pred_df.to_pickle(dataset.split(\".pkl\")[0] + \"_pred_bert.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38_histLM)",
   "language": "python",
   "name": "py38_histlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
