{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c22c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import glob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd92891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_jsa\n",
    "from utils import process_rsc\n",
    "from utils import process_hmd\n",
    "from utils import process_blbooks\n",
    "from utils import prepare_sents\n",
    "from utils import explore_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the query tokens here:\n",
    "query = \"machine\"\n",
    "min_year = 1783\n",
    "max_year = 1908"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e163ca76",
   "metadata": {},
   "source": [
    "#### Process  the JSA corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../workspace/data/\" # Path where JSA data is located\n",
    "output_path = \"data/jsa_processed/\"\n",
    "overwrite = False # If False, run the code only if output has not been created.\n",
    "                  # If True, run the code regardless.\n",
    "\n",
    "process_jsa.parse_corpus(input_path, output_path, overwrite)\n",
    "\n",
    "jsa_sents_df = prepare_sents.filter_sents_query(\"JSA\", query)\n",
    "jsa_sents_df = jsa_sents_df[(jsa_sents_df[\"year\"] >= min_year) & (jsa_sents_df[\"year\"] <= max_year)]\n",
    "jsa_sents_df.to_csv(\"data/jsa_processed/JSA_\" + query + \".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2c3a9",
   "metadata": {},
   "source": [
    "#### Process the RSC corpus\n",
    "\n",
    "Data downloaded from https://fedora.clarin-d.uni-saarland.de/rsc_v6/access.html#download.\n",
    "\n",
    "We are using:\n",
    "* TEI-formatted corpus [v6.0.4](https://fedora.clarin-d.uni-saarland.de/rsc_v6/data/texts/Royal_Society_Corpus_open_v6.0.4_texts_tei.zip) (as separate files).\n",
    "* Corresponding metadata [v6.0.4](https://fedora.clarin-d.uni-saarland.de/rsc_v6/data/Royal_Society_Corpus_open_v6.0.4_meta.tsv.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../workspace/data/RSC/\" # Path where RSC data is located\n",
    "output_path = \"data/rsc_processed/\"\n",
    "overwrite = False # If False, run the code only if output has not been created.\n",
    "                  # If True, run the code regardless.\n",
    "\n",
    "process_rsc.parse_corpus(input_path, output_path, overwrite)\n",
    "\n",
    "rsc_sents_df = prepare_sents.filter_sents_query(\"RSC\", query)\n",
    "rsc_sents_df = rsc_sents_df[(rsc_sents_df[\"year\"] >= min_year) & (rsc_sents_df[\"year\"] <= max_year)]\n",
    "rsc_sents_df.to_csv(\"data/rsc_processed/RSC_\" + query + \".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf1c38",
   "metadata": {},
   "source": [
    "#### Process the HMD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94012204",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmd_metadata_df = process_hmd.read_metadata(\"data/hmd_processed/HMD_metadata_all.csv\")\n",
    "\n",
    "hmd_dfs = []\n",
    "for i in glob.glob(\"data/hmd_processed/hmd_data/*.csv\"): # Files exported by Kaspar\n",
    "    hmd_dfs.append(process_hmd.process_content(i, query, hmd_metadata_df))\n",
    "    \n",
    "hmd_main_df = pd.concat(hmd_dfs, axis=0, ignore_index=True)\n",
    "hmd_main_df = hmd_main_df[(hmd_main_df[\"year\"] >= min_year) & (hmd_main_df[\"year\"] <= max_year)]\n",
    "hmd_main_df.to_csv(\"data/hmd_processed/HMD_\" + query + \".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1abbb",
   "metadata": {},
   "source": [
    "#### Process the BLBooks corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69914b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blb_metadata_df = process_blbooks.read_metadata(\"data/blb_processed/book_data.json\") # File provided by Kaspar\n",
    "blb_main_df = process_blbooks.process_content(\"data/blb_processed/bl_books.csv\", query, blb_metadata_df)  # File provided by Kaspar\n",
    "\n",
    "# Filter by date:\n",
    "blb_main_df = blb_main_df[blb_main_df[\"date\"].str.isnumeric()]\n",
    "blb_main_df = blb_main_df[(blb_main_df[\"date\"].astype(int) >= 1783) & (blb_main_df[\"date\"].astype(int) <= 1908)]\n",
    "\n",
    "blb_main_df.to_csv(\"data/blb_processed/BLB_\" + query + \".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe841b",
   "metadata": {},
   "source": [
    "#### Linguistic filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26292a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"jsa\", \"rsc\", \"hmd\", \"blb\"]:\n",
    "    syndf = pd.read_csv(\"data/\" + dataset + \"_processed/\" + dataset.upper() + \"_\" + query + \".tsv\", sep=\"\\t\")\n",
    "    syndf['synt'] = prepare_sents.preprocess_pipe(syndf['currentSentence'], nlp)\n",
    "    syndf = syndf[syndf.apply(lambda x: prepare_sents.filter_sents_synt(x.synt, x.maskedSentence, x.targetExpression), axis=1)]\n",
    "    syndf[\"query_label\"] = syndf.apply(lambda x: prepare_sents.find_query_deplabel(x.synt, x.maskedSentence, x.targetExpression), axis=1)\n",
    "    syndf.to_pickle(\"data/\" + dataset + \"_processed/\" + dataset.upper() + \"_\" + query + \"_synparsed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd674fad",
   "metadata": {},
   "source": [
    "#### BERT masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"data/rsc_processed/RSC_\" + query + \"_synparsed.pkl\",\n",
    "                \"data/jsa_processed/JSA_\" + query + \"_synparsed.pkl\",\n",
    "                \"data/hmd_processed/HMD_\" + query + \"_synparsed.pkl\",\n",
    "                \"data/blb_processed/BLB_\" + query + \"_synparsed.pkl\"]:\n",
    "    \n",
    "    if not Path(dataset.split(\".pkl\")[0] + \"_pred_bert.pkl\").is_file():\n",
    "        \n",
    "        print(dataset)\n",
    "\n",
    "        # Load dataframe where to apply this:\n",
    "        pred_df = pd.read_pickle(dataset)\n",
    "        for epoch in [\"1760_1850\", \"1890_1900\"]:\n",
    "\n",
    "            print(\"*\", epoch)\n",
    "\n",
    "            # Create pipeline depending on the BERT model of the specified period\n",
    "            # and the number of expected predictions:\n",
    "            pred_toks = 20\n",
    "            model_rd = explore_preds.create_mask_pipeline(epoch, pred_toks)\n",
    "\n",
    "            # Use BERT to find most likely predictions for a mask:\n",
    "            pred_df[\"pred_bert_\" + epoch] = pred_df.apply(lambda x: explore_preds.bert_masking(x, model_rd), axis=1)\n",
    "            \n",
    "            pred_df.to_pickle(dataset.split(\".pkl\")[0] + \"_\" + epoch + \"_pred_bert.pkl\")\n",
    "\n",
    "        pred_df.to_pickle(dataset.split(\".pkl\")[0] + \"_pred_bert.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38_histLM)",
   "language": "python",
   "name": "py38_histlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
