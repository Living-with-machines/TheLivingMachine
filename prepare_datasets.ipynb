{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997a4063",
   "metadata": {},
   "source": [
    "# Prepare datasets\n",
    "\n",
    "This notebook prepares the datasets to the format needed by the subsequent notebooks to process and analyse the data.\n",
    "\n",
    "Note that you will not be able to run this notebook if you don't have the original data.\n",
    "\n",
    "You can find an example file produced by this notebook in the `data/example_processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13114b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spacy model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils\n",
    "from utils import process_jsa\n",
    "from utils import process_hmd\n",
    "from utils import process_blbooks\n",
    "from utils import prepare_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the query tokens here. Change the query to see the results for a different\n",
    "# target word:\n",
    "query = \"machine\" \n",
    "min_year = 1783\n",
    "max_year = 1908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary maps the query to the name that will be displayed in the output file.\n",
    "generic = {\"machine\": \"machine\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary maps the query to the tokens it will be expanded to.\n",
    "query_tokens = dict()\n",
    "query_tokens[\"machine\"] = [\"machine\", \"machines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e146864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----------------------------------\n",
    "#### Process the JSA corpus\n",
    "\n",
    "print(\"Process the JSA corpus\")\n",
    "\n",
    "input_path = \"../../workspace/data/\" # Path where JSA data is located\n",
    "output_path = \"data/jsa_processed/\"\n",
    "overwrite = False # If False, run the code only if output has not been created.\n",
    "                  # If True, run the code regardless.\n",
    "\n",
    "process_jsa.parse_corpus(input_path, output_path, overwrite)\n",
    "\n",
    "jsa_sents_df = prepare_sents.filter_sents_query(\"JSA\", query_tokens[query])\n",
    "jsa_sents_df = jsa_sents_df[(jsa_sents_df[\"year\"] >= min_year) & (jsa_sents_df[\"year\"] <= max_year)]\n",
    "jsa_sents_df.to_csv(\"data/jsa_processed/JSA_\" + query + \".tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----------------------------------\n",
    "#### Process the HMD dataset\n",
    "\n",
    "print(\"Process the HMD corpus\")\n",
    "\n",
    "hmd_metadata_df = process_hmd.read_metadata(\"data/hmd_processed/HMD_metadata_all.csv\")\n",
    "\n",
    "hmd_dfs = []\n",
    "for i in glob.glob(\"data/hmd_processed/hmd_data_\" + generic[query] + \"_words/*.csv\"): # Files exported by Kaspar\n",
    "    hmd_dfs.append(process_hmd.process_content(i, query_tokens[query], hmd_metadata_df))\n",
    "    \n",
    "hmd_main_df = pd.concat(hmd_dfs, axis=0, ignore_index=True)\n",
    "hmd_main_df = hmd_main_df[(hmd_main_df[\"year\"] >= min_year) & (hmd_main_df[\"year\"] <= max_year)]\n",
    "hmd_main_df.to_csv(\"data/hmd_processed/HMD_\" + query + \".tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc331d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----------------------------------\n",
    "#### Process the BLBooks corpus\n",
    "print(\"Process the BLB corpus\")\n",
    "\n",
    "blb_metadata_df = process_blbooks.read_metadata(\"data/blb_processed/book_data.json\") # File provided by Kaspar\n",
    "blb_main_df = process_blbooks.process_content(\"data/blb_processed/bl_books_\" + generic[query] + \"_words.csv\", query_tokens[query], blb_metadata_df)  # File provided by Kaspar\n",
    "\n",
    "# Filter by date:\n",
    "blb_main_df = blb_main_df[blb_main_df[\"date\"].str.isnumeric()]\n",
    "blb_main_df = blb_main_df[(blb_main_df[\"date\"].astype(int) >= 1783) & (blb_main_df[\"date\"].astype(int) <= 1908)]\n",
    "\n",
    "blb_main_df.to_csv(\"data/blb_processed/BLB_\" + query + \".tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39tlm)",
   "language": "python",
   "name": "py39tlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
