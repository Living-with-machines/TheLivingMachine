{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import syntok.segmenter as segmenter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../Lab1/blbook_explorer/json/')\n",
    "save_to = Path('bl_books_data_ext')\n",
    "save_to.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = re.compile(r'(?:\\bmachine[s]{,1}\\b|\\bengine[s]{,1}\\b)',re.I)\n",
    "#pattern = re.compile(r'(?:\\bwom[ea]n\\b|\\bboy[s]{,1}\\b|\\bart[ie][zs]an\\b|\\bslave[s]{,1}\\b)')\n",
    "#pattern = re.compile(r'(?:\\bgirl[s]{,1}\\b)')\n",
    "pattern = re.compile(r'(?:\\bgirl[s]{,1}\\b|\\bart[ie][zs]an[s]{,1}\\b)')\n",
    "#pattern.findall('machine Machines Mdachine dmachines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63985"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files = list(path.glob('**/*.json'))\n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvest_sentences(text,path, regex_pattern):\n",
    "    if regex_pattern.findall(text):\n",
    "        sentences = [' '.join([t.value for t in s]) \n",
    "                            for p in segmenter.process(text) for s in p\n",
    "                                ]\n",
    "        sentences = [\"<START>\"] + sentences + [\"<END>\"]\n",
    "        \n",
    "        target_sents = [(path,\n",
    "                        sentences[i-1],\n",
    "                        sentences[i],\n",
    "                        sentences[i+1],\n",
    "                        '<SEP>'.join(\n",
    "                                set(regex_pattern.findall(s)))\n",
    "                                     )\n",
    "                                    for i,s in enumerate(sentences) \n",
    "                                             if regex_pattern.findall(s)\n",
    "                                ]\n",
    "        return target_sents\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1017c59269f421b8237b006144f60a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63985.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1799907\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "rows = []\n",
    "\n",
    "for js in tqdm(json_files):\n",
    "    with open(js, 'r') as in_json:\n",
    "        data = json.load(in_json)\n",
    "        pages = [str(t) for p,t in data]\n",
    "        if pattern.findall(' '.join(pages)):\n",
    "            pages = [\"<START>\"] + pages + ['<END>']\n",
    "            for j,page in enumerate(pages):\n",
    "                \n",
    "                if pattern.findall(page):\n",
    "                    \n",
    "                    text = ' '.join([pages[j-1],pages[j],pages[j+1]])\n",
    "                    target_sentences = harvest_sentences(text,js.name,regex_pattern=pattern)\n",
    "                    if target_sentences:\n",
    "                        \n",
    "                        rows.extend(target_sentences)\n",
    "                        count+=len(target_sentences)\n",
    "                \n",
    "df = pd.DataFrame(rows,columns=['article_path','previous_sentence','target_sentence','next_sentence','hits'])\n",
    "df.to_csv(save_to / 'bl_books_extension_words.csv')\n",
    "                    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
